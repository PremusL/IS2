{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ijson\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#podatki iz jsona\n",
    "\n",
    "file_path = \"./News_Category_Dataset_IS_course.json\"\n",
    "# file_path = \"./test.json\"\n",
    "\n",
    "data = [json.loads(line, object_hook=lambda o: str(o) if isinstance(o, (str, type(None)))else o) for line in open(file_path, 'r')]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naredi dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "categories = df['category'].value_counts()\n",
    "\n",
    "num_categories = len(categories)\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds the whole story to the dataframe\n",
    "\n",
    "def add_story(df):\n",
    "    text_column = []\n",
    "\n",
    "    for i in range(15360, len(df)):\n",
    "        # print(f\"index: {i}\")\n",
    "        short_description = df['short_description'].iloc[i]\n",
    "\n",
    "        if (type(short_description) != str):\n",
    "            # print(short_description)\n",
    "            print(f\"index {i}\")\n",
    "            link = df['link'].iloc[i]\n",
    "            try:\n",
    "                response = requests.get(link)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                    # section = soup.find('section')\n",
    "                    cur_text_arr = []\n",
    "                    all_data_article = soup.find_all('div', class_='primary-cli') #all the text data in article that could be useful (the last few aren't)\n",
    "                    for i in range(len(all_data_article) - 2):\n",
    "                        k = all_data_article[i]\n",
    "                        cur_text_arr.append(k.text)\n",
    "                    current_string = \" \".join(cur_text_arr)\n",
    "\n",
    "                    df.at[i, 'short_description'] = current_string\n",
    "            \n",
    "            except:\n",
    "                continue\n",
    "                # text_column.append(current_string)\n",
    "\n",
    "    \n",
    "\n",
    "    # df['story'] = text_column\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# links\n",
    "\n",
    "stories = add_story(df)\n",
    "\n",
    "stories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories.to_csv(\"fixed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into words\n",
    "    text = str(text)\n",
    "    words = word_tokenize(text.lower())  # Convert text to lowercase\n",
    "\n",
    "    # Remove punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    words = [word.translate(table) for word in words if word.isalpha()]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Stemming (uncomment if you want to use stemming)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Join the words back into a string\n",
    "    preprocessed_text = ' '.join(lemmatized_words)\n",
    "    return preprocessed_text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./fixed_data.csv', sep=',')\n",
    "# df\n",
    "# df['cleaned_text'] = df['short_description'].apply(preprocess_text)\n",
    "# df['cleaned_headline'] = df['headline'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_information'] = df['cleaned_text'].astype(str).str.cat(df['cleaned_headline'].astype(str),sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"fixed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./fixed_data.csv\", sep=',')\n",
    "data = data.sample(frac=1, random_state=42)\n",
    "data = data.dropna()\n",
    "# data = data.fillna('')\n",
    "\n",
    "# data['cleaned_text'] = data['cleaned_text'].fillna('')\n",
    "\n",
    "\n",
    "data['cleaned_information']\n",
    "# data['headline']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'data' is your DataFrame and 'category' is the column of interest\n",
    "category_counts = data['category'].value_counts()\n",
    "\n",
    "# Plotting the pie chart with percent values\n",
    "category_counts.plot(kind='pie', figsize=(6, 6), autopct='%1.1f%%')\n",
    "\n",
    "plt.title('Category Distribution')\n",
    "plt.ylabel('')  # Remove y-axis label for better clarity\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['cleaned_information', 'short_description', 'headline']], data['category'], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer()  # Use TF-IDF vectorizer for text to numerical feature conversion\n",
    "X_train_vec = vectorizer.fit_transform(X_train['cleaned_information'])\n",
    "X_test_vec = vectorizer.transform(X_test['cleaned_information'])\n",
    "\n",
    "tokenized_train_text = [text.split() for text in X_train['cleaned_information']]\n",
    "tokenized_test_text = [text.split() for text in X_test['cleaned_information']]\n",
    "\n",
    "\n",
    "# tokenized_test_text\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Logistic Regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train_vec, y_train)\n",
    "logistic_predictions = logistic_model.predict(X_test_vec)\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "print(\"Logistic Regression Accuracy:\", logistic_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Random Forest model slabsi je\n",
    "# rf_model = RandomForestClassifier()\n",
    "# rf_model.fit(X_train_vec, y_train)\n",
    "# rf_predictions = rf_model.predict(X_test_vec)\n",
    "# rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "# print(\"Random Forest Accuracy:\", rf_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "w2v_model = Word2Vec(tokenized_train_text, vector_size=100, window=5, min_count=1, workers=6, epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = w2v_model.wv.index_to_key\n",
    "\n",
    "\n",
    "categories = [cat.lower() for cat in data['category'].unique().tolist()]\n",
    "print(categories)\n",
    "\n",
    "word_vectors_dict = {word: w2v_model.wv[word] for word in all_words}\n",
    "# category_vectors = [w2v_model.wv[word] for word in categories]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = [w2v_model.wv[word] for word in all_words]\n",
    "print(word_vectors)\n",
    "\n",
    "\n",
    "# logistic_model = LogisticRegression()\n",
    "# logistic_model.fit(word_vectors, y_train)\n",
    "# logistic_predictions = logistic_model.predict(X_test_vec)\n",
    "# logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "# print(\"Logistic Regression Accuracy:\", logistic_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vector(text, model):\n",
    "    words = word_tokenize(text.lower())\n",
    "    vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if not vectors:\n",
    "        return None\n",
    "    return sum(vectors) / len(vectors)\n",
    "\n",
    "tokenized_texts = [word_tokenize(text.lower()) for text in data['cleaned_information']]\n",
    "model = Word2Vec(tokenized_texts, vector_size=100, window=20, min_count=1, workers=8, epochs=15)\n",
    "# Assuming 'texts' is a list of sentences\n",
    "vectors = [text_to_vector(text, model) for text in data['cleaned_information']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Assuming 'labels' is a list of class labels\n",
    "cat = data['category']\n",
    "# print(cat, len(cat), len(vectors))\n",
    "filter_vec = list(filter(lambda v: v is not None, vectors))\n",
    "filter_cat = [cat.iloc[i] for i,v in enumerate(vectors) if v is not None]\n",
    "X_train, X_test, y_train, y_test = train_test_split(filter_vec, np.array(filter_cat), test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a classifier\n",
    "classifier = LogisticRegression(max_iter=4000)\n",
    "\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "cv_scores = cross_val_score(classifier, X_train, y_train, cv=7)\n",
    "print(f'Cross-Validation Scores: {cv_scores}')\n",
    "print(f'Mean CV Accuracy: {cv_scores.mean():.2f}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'POLITICS': 0, 'TRAVEL':1, 'WELLNESS':2, 'BUSINESS':3, 'BLACK VOICES':4, 'HEALTHY LIVING':5,\n",
    " 'ENTERTAINMENT':6, 'QUEER VOICES':7, 'COMEDY':8, 'STYLE & BEAUTY':9, 'FOOD & DRINK':10,\n",
    " 'SPORTS':11, 'HOME & LIVING':12, 'PARENTING':13, 'PARENTS':14}\n",
    "train_data_1 = pd.DataFrame()\n",
    "train_data_1['category'] = data['category'].map(label_mapping).copy()\n",
    "train_data_1['category'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# cat = data['category']\n",
    "# print(cat, len(cat), len(vectors))\n",
    "filter_vec = list(filter(lambda v: v is not None, vectors))\n",
    "# filter_cat = [cat.iloc[i] for i,v in enumerate(vectors) if v is not None]\n",
    "X_train, X_test, y_train, y_test = train_test_split(filter_vec, np.array(train_data_1['category']), test_size=0.2, random_state=42)\n",
    "# print(X_train)\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "paramter_grid = {\n",
    "    'learning_rate': [0.01,0.1,0.2],\n",
    "    'n_estimators': [50,100,200],\n",
    "    'max_depth': [3,4,5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model,param_grid=paramter_grid,cv=3,scoring='accuracy',n_jobs=8)\n",
    "grid_search.fit(X_train,y_train)\n",
    "best_paramters = grid_search.best_params_\n",
    "\n",
    "\n",
    "final_model = XGBClassifier(**best_paramters)\n",
    "final_model.fit(X_train,y_train)\n",
    "\n",
    "make_predictions = final_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,make_predictions)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_paramters)\n",
    "print(\"Test Set Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Extract text and labels\n",
    "# texts = [doc['cleaned_information'] for doc in data]\n",
    "# labels = [doc['category'] for doc in data]\n",
    "texts = data['cleaned_information']\n",
    "labels = data['category']\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "# Create a Bag-of-Words representation of the text\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 1.5, 2.0], \n",
    "}\n",
    "\n",
    "# Train a classifier (for example, Naive Bayes)\n",
    "classifier = MultinomialNB()\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_bow,y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n",
    "print(f'Best Cross-Validation Accuracy: {grid_search.best_score_:.2f}')\n",
    "\n",
    "\n",
    "# classifier.fit(X_train_bow, y_train)\n",
    "\n",
    "# Get the best classifier from grid search\n",
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = best_classifier.predict(X_test_bow)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Display classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"Lets watch tennis\"]\n",
    "X_test_bow = vectorizer.transform(texts)\n",
    "\n",
    "predictions = best_classifier.predict(X_test_bow)\n",
    "print(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Extract text and labels\n",
    "# texts = [doc['cleaned_information'] for doc in data]\n",
    "# labels = [doc['category'] for doc in data]\n",
    "texts = data['cleaned_information']\n",
    "labels = data['category']\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "# Create a Bag-of-Words representation of the text\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150], \n",
    "    'max_depth': [None,10, 20, 30],  \n",
    "}\n",
    "\n",
    "# Train a classifier (for example, Naive Bayes)\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_bow,y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n",
    "print(f'Best Cross-Validation Accuracy: {grid_search.best_score_:.2f}')\n",
    "\n",
    "\n",
    "# classifier.fit(X_train_bow, y_train)\n",
    "\n",
    "# Get the best classifier from grid search\n",
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = best_classifier.predict(X_test_bow)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Display classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
